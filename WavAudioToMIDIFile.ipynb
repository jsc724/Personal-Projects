{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sound_to_midi as sm\n",
    "import sys\n",
    "import numpy as np\n",
    "import librosa\n",
    "import midiutil\n",
    "import os\n",
    "from scipy import signal\n",
    "import scipy\n",
    "import random\n",
    "import time\n",
    "from datetime import timedelta as td\n",
    "import music21\n",
    "import scipy.io.wavfile\n",
    "import wave\n",
    "import struct\n",
    "import soundfile\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(\n",
    "        note_min: str,\n",
    "        note_max: str,\n",
    "        p_stay_note: float,\n",
    "        p_stay_silence: float) -> np.array:\n",
    "\n",
    "    midi_min = librosa.note_to_midi(note_min)\n",
    "    midi_max = librosa.note_to_midi(note_max)\n",
    "    n_notes = midi_max - midi_min + 1\n",
    "    p_l = (1 - p_stay_silence) / n_notes\n",
    "    p_ll = (1 - p_stay_note) / (n_notes + 1)\n",
    "\n",
    "    # Transition matrix:\n",
    "    # State 0 = silence\n",
    "    # States 1, 3, 5... = onsets\n",
    "    # States 2, 4, 6... = sustains\n",
    "    transmat = np.zeros((2 * n_notes + 1, 2 * n_notes + 1))\n",
    "\n",
    "    # State 0: silence\n",
    "    transmat[0, 0] = p_stay_silence\n",
    "    for i in range(n_notes):\n",
    "        transmat[0, (i * 2) + 1] = p_l\n",
    "\n",
    "    # States 1, 3, 5... = onsets\n",
    "    for i in range(n_notes):\n",
    "        transmat[(i * 2) + 1, (i * 2) + 2] = 1\n",
    "\n",
    "    # States 2, 4, 6... = sustains\n",
    "    for i in range(n_notes):\n",
    "        transmat[(i * 2) + 2, 0] = p_ll\n",
    "        transmat[(i * 2) + 2, (i * 2) + 2] = p_stay_note\n",
    "        for j in range(n_notes):\n",
    "            transmat[(i * 2) + 2, (j * 2) + 1] = p_ll\n",
    "\n",
    "    return transmat\n",
    "\n",
    "\n",
    "def prior_probabilities(\n",
    "        audio_signal: np.array,\n",
    "        note_min: str,\n",
    "        note_max: str,\n",
    "        srate: int,\n",
    "        frame_length: int = 2048,\n",
    "        hop_length: int = 512,\n",
    "        pitch_acc: float = 0.9,\n",
    "        voiced_acc: float = 0.9,\n",
    "        onset_acc: float = 0.9,\n",
    "        spread: float = 0.2) -> np.array:\n",
    "\n",
    "    fmin = librosa.note_to_hz(note_min)\n",
    "    fmax = librosa.note_to_hz(note_max)\n",
    "    midi_min = librosa.note_to_midi(note_min)\n",
    "    midi_max = librosa.note_to_midi(note_max)\n",
    "    n_notes = midi_max - midi_min + 1\n",
    "\n",
    "    # pitch and voicing\n",
    "    pitch, voiced_flag, _ = librosa.pyin(\n",
    "        y=audio_signal, fmin=fmin * 0.9, fmax=fmax * 1.1,\n",
    "        sr=srate, frame_length=frame_length, win_length=int(frame_length / 2),\n",
    "        hop_length=hop_length)\n",
    "    tuning = librosa.pitch_tuning(pitch)\n",
    "    f0_ = np.round(librosa.hz_to_midi(pitch - tuning)).astype(int)\n",
    "    onsets = librosa.onset.onset_detect(\n",
    "        y=audio_signal, sr=srate,\n",
    "        hop_length=hop_length, backtrack=True)\n",
    "\n",
    "    priors = np.ones((n_notes * 2 + 1, len(pitch)))\n",
    "\n",
    "    for n_frame in range(len(pitch)):\n",
    "        # probability of silence or onset = 1-voiced_prob\n",
    "        # Probability of a note = voiced_prob * (pitch_acc) (estimated note)\n",
    "        # Probability of a note = voiced_prob * (1-pitch_acc) (estimated note)\n",
    "        if not voiced_flag[n_frame]:\n",
    "            priors[0, n_frame] = voiced_acc\n",
    "        else:\n",
    "            priors[0, n_frame] = 1 - voiced_acc\n",
    "\n",
    "        for j in range(n_notes):\n",
    "            if n_frame in onsets:\n",
    "                priors[(j * 2) + 1, n_frame] = onset_acc\n",
    "            else:\n",
    "                priors[(j * 2) + 1, n_frame] = 1 - onset_acc\n",
    "\n",
    "            if j + midi_min == f0_[n_frame]:\n",
    "                priors[(j * 2) + 2, n_frame] = pitch_acc\n",
    "\n",
    "            elif np.abs(j + midi_min - f0_[n_frame]) == 1:\n",
    "                priors[(j * 2) + 2, n_frame] = pitch_acc * spread\n",
    "\n",
    "            else:\n",
    "                priors[(j * 2) + 2, n_frame] = 1 - pitch_acc\n",
    "\n",
    "    return priors\n",
    "\n",
    "\n",
    "def states_to_pianoroll(states: list, note_min: str, hop_time: float) -> list:\n",
    "    midi_min = librosa.note_to_midi(note_min)\n",
    "\n",
    "    states_ = np.hstack((states, np.zeros(1)))\n",
    "\n",
    "    # possible types of states\n",
    "    silence = 0\n",
    "    onset = 1\n",
    "    sustain = 2\n",
    "\n",
    "    my_state = silence\n",
    "    output = []\n",
    "\n",
    "    last_onset = 0\n",
    "    last_offset = 0\n",
    "    last_midi = 0\n",
    "    for i, _ in enumerate(states_):\n",
    "        if my_state == silence:\n",
    "            if int(states_[i] % 2) != 0:\n",
    "                # Found an onset!\n",
    "                last_onset = i * hop_time\n",
    "                last_midi = ((states_[i] - 1) / 2) + midi_min\n",
    "                last_note = librosa.midi_to_note(last_midi)\n",
    "                my_state = onset\n",
    "\n",
    "        elif my_state == onset:\n",
    "            if int(states_[i] % 2) == 0:\n",
    "                my_state = sustain\n",
    "\n",
    "        elif my_state == sustain:\n",
    "            if int(states_[i] % 2) != 0:\n",
    "                # Found an onset.\n",
    "                # Finish last note\n",
    "                last_offset = i * hop_time\n",
    "                my_note = [last_onset, last_offset, last_midi, last_note]\n",
    "                output.append(my_note)\n",
    "\n",
    "                # Start new note\n",
    "                last_onset = i * hop_time\n",
    "                last_midi = ((states_[i] - 1) / 2) + midi_min\n",
    "                last_note = librosa.midi_to_note(last_midi)\n",
    "                my_state = onset\n",
    "\n",
    "            elif states_[i] == 0:\n",
    "                # Found silence. Finish last note.\n",
    "                last_offset = i * hop_time\n",
    "                my_note = [last_onset, last_offset, last_midi, last_note]\n",
    "                output.append(my_note)\n",
    "                my_state = silence\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def pianoroll_to_midi(bpm: float, pianoroll: list) -> midiutil.MIDIFile():\n",
    "    quarter_note = 60 / bpm\n",
    "\n",
    "    onsets = np.array([p[0] for p in pianoroll])\n",
    "    offsets = np.array([p[1] for p in pianoroll])\n",
    "\n",
    "    onsets = onsets / quarter_note\n",
    "    offsets = offsets / quarter_note\n",
    "    durations = offsets - onsets\n",
    "\n",
    "    midi = midiutil.MIDIFile(1)\n",
    "    midi.addTempo(0, 0, bpm)\n",
    "\n",
    "    for i, _ in enumerate(onsets):\n",
    "        midi.addNote(\n",
    "            0, 0, int(pianoroll[i][2]), onsets[i], durations[i], 100)\n",
    "\n",
    "    return midi\n",
    "\n",
    "def wave_to_midi(\n",
    "        audio_signal: np.array,\n",
    "        srate: int = 16000,\n",
    "        frame_length: int = 2048,\n",
    "        hop_length: int = 512,\n",
    "        note_min: str = \"A2\",\n",
    "        note_max: str = \"E8\",\n",
    "        p_stay_note: float = 0.9,\n",
    "        p_stay_silence: float = 0.7,\n",
    "        pitch_acc: float = 0.9,\n",
    "        voiced_acc: float = 0.9,\n",
    "        onset_acc: float = 0.9,\n",
    "        spread: float = 0.2) -> midiutil.MIDIFile():\n",
    "    transmat = transition_matrix(note_min, note_max, p_stay_note, p_stay_silence)\n",
    "    priors = prior_probabilities(\n",
    "        audio_signal,\n",
    "        note_min,\n",
    "        note_max,\n",
    "        srate,\n",
    "        frame_length,\n",
    "        hop_length,\n",
    "        pitch_acc,\n",
    "        voiced_acc,\n",
    "        onset_acc,\n",
    "        spread)\n",
    "    p_init = np.zeros(transmat.shape[0])\n",
    "    p_init[0] = 1\n",
    "    states = librosa.sequence.viterbi(priors, transmat, p_init=p_init)\n",
    "\n",
    "    pianoroll = states_to_pianoroll(states, note_min, hop_length / srate)\n",
    "    bpm = librosa.beat.tempo(y=audio_signal)[0]\n",
    "    midi = pianoroll_to_midi(bpm, pianoroll)\n",
    "\n",
    "    return midi\n",
    "\n",
    "def f_high(y,sr):\n",
    "    b,a = signal.butter(10, 2000/(sr/2), btype='highpass')\n",
    "    yf = signal.lfilter(b,a,y)\n",
    "    return yf\n",
    "\n",
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)\n",
    "\n",
    "def _db_to_amp(x,):\n",
    "    return librosa.core.db_to_amplitude(x, ref=1.0)\n",
    "\n",
    "def removeNoise(\n",
    "    audio_clip,\n",
    "    noise_clip,\n",
    "    n_grad_freq=2,\n",
    "    n_grad_time=4,\n",
    "    n_fft=2048,\n",
    "    win_length=2048,\n",
    "    hop_length=512,\n",
    "    n_std_thresh=1.5,\n",
    "    prop_decrease=1.0,\n",
    "    verbose=False,\n",
    "    visual=False,\n",
    "):\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # convert to dB\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis=1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis=1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint=False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "    )\n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    db_thresh = np.repeat(\n",
    "        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "        np.shape(sig_stft_db)[1],\n",
    "        axis=0,\n",
    "    ).T\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    sig_stft_db_masked = (\n",
    "        sig_stft_db * (1 - sig_mask)\n",
    "        + np.ones(np.shape(mask_gain_dB)) * mask_gain_dB * sig_mask\n",
    "    )  # mask real\n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (\n",
    "        1j * sig_imag_masked\n",
    "    )\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "    # recover the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds=time.time() - start))\n",
    "    return recovered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakes\\AppData\\Local\\Temp\\ipykernel_22328\\3437743545.py:212: FutureWarning: Pass hop_length=512, win_length=2048 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.istft(y, hop_length, win_length)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise removal finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakes\\AppData\\Local\\Temp\\ipykernel_22328\\3437743545.py:87: RuntimeWarning: overflow encountered in long_scalars\n",
      "  elif np.abs(j + midi_min - f0_[n_frame]) == 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion finished!\n",
      "Done generating MIDI\n",
      "C# minor\n"
     ]
    }
   ],
   "source": [
    "file_in = 'C:/Users/jakes/Music/PythonStems/Eros/vocals.wav'\n",
    "path_out = 'C:/Users/jakes/Music/PythonMIDIs/Eros/'\n",
    "path_out2 = 'C:/Users/jakes/Music/PythonStems/Eros/'\n",
    "file_out = 'vocalMIDI.mid'\n",
    "file_out2 = 'cleanvocals.wav'\n",
    "y, sr = librosa.load(file_in, sr=16000)\n",
    "print(\"Audio file loaded!\")\n",
    "noise1 = y[0:1*sr]\n",
    "yadj = removeNoise(audio_clip=y, noise_clip=noise1,\n",
    "    n_grad_freq=2,\n",
    "    n_grad_time=4,\n",
    "    n_fft=2048,\n",
    "    win_length=2048,\n",
    "    hop_length=512,\n",
    "    n_std_thresh=5,\n",
    "    prop_decrease=1.0,\n",
    "    verbose=False,\n",
    "    visual=False)\n",
    "try:\n",
    "    os.chdir(path_out2)\n",
    "except (FileNotFoundError,FileExistsError):\n",
    "    os.makedirs(path_out2)\n",
    "soundfile.write(path_out2+file_out2, yadj, 16000)\n",
    "print(\"Noise removal finished!\")\n",
    "midi = wave_to_midi(yadj, srate=sr)\n",
    "print(\"Conversion finished!\")\n",
    "try:\n",
    "    os.chdir(path_out)\n",
    "except (FileNotFoundError,FileExistsError):\n",
    "    os.makedirs(path_out)\n",
    "with open(os.path.join(path_out, file_out), 'wb') as fp:\n",
    "    midi.writeFile(fp)\n",
    "print(\"Done generating MIDI\")\n",
    "score = music21.converter.parse('C:/Users/jakes/Music/PythonMIDIs/Calling/vocalMIDI.mid')\n",
    "key = score.analyze('key')\n",
    "print(key.tonic.name, key.mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "474494322f58e04feada64ebef398262cdf533ed46e9795a581426af4f5decd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
